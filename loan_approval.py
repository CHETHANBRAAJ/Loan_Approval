# -*- coding: utf-8 -*-
"""Loan approval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11K8JTHwVk_GezX-bJEpqusqu2Z-5uefP
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.preprocessing import OrdinalEncoder
from matplotlib import pyplot as plt
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

encode=OrdinalEncoder()

df=pd.read_csv("/content/Loan_approval.csv")

df.info()

df.head()

df.Gender.unique()

df['Gender']=encode.fit_transform(df[['Gender']])

df.head()

df.Gender.unique()

df['Married']=df['Married'].map({'No':0,'Yes':1,'nan':2})

#df[df.isnull().any(axis=1)]
# df[df.isnull()]
df['Gender'].isnull().sum()

df.Married.unique()

df['Married'].isnull().sum()

df.Dependents.unique()

df.Education.unique()

df['Education']=encode.fit_transform(df[['Education']])

df.Education.unique()

df['Education'].isnull().sum()
#Education is clear

df.Self_Employed.unique()

df["Self_Employed"].isnull().sum()

df["Self_Employed"].value_counts()

df['ApplicantIncome'].isnull().sum()
#ApplicantIncome is clear

df['CoapplicantIncome'].isnull().sum()
#CoapplicantIncome is clear

df['LoanAmount'].isnull().sum()

df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)

df['LoanAmount'].isnull().sum()
#Loan_amount is clear

df['Loan_Amount_Term'].isnull().sum()

df['Loan_Amount_Term'].fillna(df['LoanAmount'].mean(),inplace=True)

df['Loan_Amount_Term'].isnull().sum()
#LoanAmount_term is clear

df['Credit_History'].isnull().sum()

df.Credit_History.unique()

df['Credit_History'].fillna(df['Credit_History'].mean(),inplace=True)

df.head()

df['Credit_History'].isnull().sum()
#Credit_history clear

df.Property_Area.unique()

df['Property_Area']=encode.fit_transform(df[['Property_Area']])

df.Property_Area.unique()

df['Property_Area'].value_counts()[1.0]

df.Loan_Status.unique()

df["Loan_Status"].isnull().sum()

df["Loan_Status"]=df["Loan_Status"].map({'Y':1,'N':0})

df['Self_Employed'].isnull().sum()

df = df.dropna(subset=['Self_Employed'])

df.head()

df['Self_Employed'].isnull().sum()

df.Self_Employed.unique()

df['Self_Employed']=df['Self_Employed'].map({'No':0,'Yes':1})
#sel_employed clear

df.head()

df['Gender'].isnull().sum()

df = df.dropna(subset=['Gender'])

df['Married'].isnull().sum()

df.isnull().sum()

df = df.dropna(subset=['Dependents'])

df.isnull().sum()

#X=df.drop('Loan_Status',axis=1)
#y=df['Loan_Status']

df.corr()

sns.heatmap(df.corr())

sns.heatmap(df.isnull(),cmap='icefire')

plt.figure(figsize=(5,5))
sns.countplot(x='Loan_Status',data=df,palette='deep')
plt.show()

plt.figure(figsize=(5,5))
sns.countplot(x='Loan_Status',data=df,hue='Gender',palette='deep')
plt.show()

plt.figure(figsize=(15,15))
#sns.countplot(x='Loan_Status',data=df,hue='LoanAmount',palette='deep')
plt.show()

sns.histplot(df[df['Loan_Status'] == 0]["LoanAmount"], color='green',label='Rejected')
sns.histplot(df[df['Loan_Status'] == 1]["LoanAmount"], color='red',label='Accepted')
plt.legend()
plt.show()

from ipywidgets.widgets.widget_string import Label
plt.figure(figsize=(15,15))
sns.countplot(x='Loan_Status',data=df,hue='Property_Area'
,palette='deep')
plt.show()

df.info()

df['Dependents']=df['Dependents'].map({'0':0,'1':1,'2':2,'3+':3})

df.Dependents.unique()

df['Dependents']=df['Dependents'].astype(int)

df.info()

df=df.drop("Loan_ID",axis=1)

df.to_csv("Loan_approval_cleaned",index=False)

"""#TESTING AND TRAINING"""

X=df.drop('Loan_Status',axis=1)
y=df['Loan_Status']

X.head()

y.count()

y.shape

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
pipe = Pipeline([('scaler', StandardScaler())])
pipe.fit(X_train)

X_train.head()

y_train.head()

"""# MODEL SELECTION"""

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score

from sklearn.linear_model import LogisticRegression
m1=LogisticRegression()
m1.fit(X_train,y_train)
pipe.fit(X_test,y_test)
yp1=m1.predict(X_test)


from sklearn.tree import DecisionTreeClassifier
m2=DecisionTreeClassifier()
m2.fit(X_train,y_train)
yp2=m2.predict(X_test)


from sklearn.neighbors import KNeighborsClassifier
m3=KNeighborsClassifier()
m3.fit(X_train,y_train)
yp3=m3.predict(X_test)

from sklearn.ensemble import RandomForestClassifier
m4=RandomForestClassifier()
m4.fit(X_train,y_train)
yp4=m4.predict(X_test)

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
from sklearn.metrics import classification_report,confusion_matrix
print("Logistic Regression :")
print(" accuracy is ",accuracy_score(y_test,yp1))
print(" precision score is ",precision_score(y_test,yp1))
print(" recall is ",recall_score(y_test,yp1))
print(" f1 score is ",f1_score(y_test,yp1))
print(classification_report(y_test,yp1))
print(" confusion matrix is ",confusion_matrix(y_test,yp1))

print("Decision Tree Classifier :")
print(" accuracy is ",accuracy_score(y_test,yp2))
print(" precision score is ",precision_score(y_test,yp2))
print(" recall is ",recall_score(y_test,yp2))
print(" f1 score is ",f1_score(y_test,yp2))
print(" classification report is ",classification_report(y_test,yp2))
print(" confusion matrix is ",confusion_matrix(y_test,yp2))

print("KNN" )
print(" accuracy is ",accuracy_score(y_test,yp3))
print(" precision score is ",precision_score(y_test,yp3))
print(" recall is ",recall_score(y_test,yp3))
print(" f1 score is ",f1_score(y_test,yp3))
print(" classification report is ",classification_report(y_test,yp3))
print(" confusion matrix is ",confusion_matrix(y_test,yp3))

print("Random forest:" )
print(" accuracy is ",accuracy_score(y_test,yp4))
print(" precision score is ",precision_score(y_test,yp4))
print(" recall is ",recall_score(y_test,yp4))
print(" f1 score is ",f1_score(y_test,yp4))
print(" classification report is ",classification_report(y_test,yp4))
print(" confusion matrix is ",confusion_matrix(y_test,yp4))

"""# TESTING"""

X_test.tail()

y_test.tail()

from joblib import dump,load
dump(m1,"Loan_approval_model.joblib")

import numpy as np
from joblib import dump,load
model=load("/content/Loan_approval_model.joblib")

X_test.head()

features=np.array([[1.0,0.0,4,0.0,0.0,0.0,0.0,100,120,1,1.0]])
m1.predict(features)

